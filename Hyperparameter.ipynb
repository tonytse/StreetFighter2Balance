{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29290100-5ae8-40b2-ae89-4c1bf111329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import StreetFighter as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d66557-791d-4c1a-8a7c-e7fccc799170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 0 games\n"
     ]
    }
   ],
   "source": [
    "!python3 -m retro.import ./roms # Run this from the roms folder, or where you have your game roms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3d81f5-9841-4608-8919-bff2f9d1e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import json\n",
    "# stable baseline\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "from sb3_contrib import RecurrentPPO, TRPO, QRDQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7df4d88-705e-47ae-9803-ca71ffa77fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kLearnTimesteps = 150_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13249a-fcc3-445e-b5ef-a9792a207d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dabccaa-4a6e-4391-be13-7b20d815e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_a2c_agent(trial):\n",
    "    \n",
    "    model_params = {\n",
    "        \"n_steps\": trial.suggest_int(\"n_steps\", 16, 128),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.8, 0.9999),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3),\n",
    "        \"ent_coef\": trial.suggest_float(\"ent_coef\", 1e-4, 1e-1),\n",
    "        \"vf_coef\": trial.suggest_float(\"vf_coef\", 0.01, 0.5),\n",
    "        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.1, 1)\n",
    "    }\n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = A2C('MlpPolicy', env, tensorboard_log=kLogDir, verbose=0, **model_params)\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29ed5a2d-2b18-48e0-b023-b2db781311a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_ppo_agent(trial):\n",
    "    model_params =  {\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512]),\n",
    "        \"n_steps\": trial.suggest_categorical(\"n_steps\", [64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3),\n",
    "        'clip_range': trial.suggest_float('clip_range', 0.1, 0.4),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda', 0.8, .99)\n",
    "    }\n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = PPO('MlpPolicy', env, tensorboard_log=kLogDir, verbose=0, **model_params)\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cbe5198-6bd8-4c28-8cea-c896c947c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_dqn_agent(trial):\n",
    "    model_params =  {\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [ 32, 64, 128, 256, 512, 1024]),\n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3),\n",
    "        \"learning_starts\" : trial.suggest_categorical(\"learning_starts\", [1000, 10000, 20000, 30000, 40000, 50000]),\n",
    "        \"train_freq\" : trial.suggest_categorical(\"train_freq\", [128, 256]), # Train time\n",
    "        \"gradient_steps\" : trial.suggest_int(\"gradient_steps\", 1, 256),\n",
    "        \"exploration_final_eps\" : trial.suggest_float(\"exploration_final_eps\", 0.01, 0.09),\n",
    "        \"exploration_fraction\" : trial.suggest_float(\"exploration_fraction\", 0.1, 0.5),\n",
    "        \n",
    "    }\n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = DQN('MlpPolicy', env, tensorboard_log=kLogDir, verbose=0, **model_params)\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476ddff0-8d47-4ea4-a813-83ba6c15271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rppo_agent(trial):\n",
    "    model_params = {\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [128, 256]),\n",
    "        \"n_steps\": trial.suggest_categorical(\"n_steps\", [128, 256]), \n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3),\n",
    "        'clip_range': trial.suggest_float('clip_range', 0.1, 0.4),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda', 0.8, .99),\n",
    "        \"ent_coef\": trial.suggest_float(\"ent_coef\", 1e-4, 1e-1),\n",
    "        \"vf_coef\": trial.suggest_float(\"vf_coef\", 0.01, 0.5),\n",
    "        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.1, 1)\n",
    "    }\n",
    "    \n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = RecurrentPPO('MlpLstmPolicy', env, tensorboard_log=kLogDir, verbose=0, **model_params )\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be60ec3-6afb-4a51-91f3-d491035a9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_trpo_agent(trial):\n",
    "    model_params =  {\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512]),\n",
    "        \"n_steps\": trial.suggest_categorical(\"n_steps\", [64, 128, 256, 512, 1024, 2048, 4096, 8192]),\n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
    "        'gae_lambda': trial.suggest_float('gae_lambda', 0.8, .99),\n",
    "        \"n_critic_updates\": trial.suggest_categorical(\"n_critic_updates\", [5, 10, 20, 25, 30]),\n",
    "        \"cg_max_steps\": trial.suggest_categorical(\"cg_max_steps\", [5, 10, 20, 25, 30]),\n",
    "        \"target_kl\": trial.suggest_categorical(\"target_kl\", [0.1, 0.05, 0.03, 0.02, 0.01, 0.005, 0.001])\n",
    "        \n",
    "    }\n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = TRPO(\"MlpPolicy\", env, verbose=0, tensorboard_log=kLogDir, **model_params )\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e808dec7-c485-4c4f-b943-a4809f4af2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_qrdqn_agent(trial):\n",
    "    model_params =  {\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
    "        \"learning_starts\" : trial.suggest_categorical(\"learning_starts\", [1000, 10000, 20000, 30000, 40000, 50000]),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512]),\n",
    "        'gamma': trial.suggest_float('gamma', 0.8, 0.9999),\n",
    "        \"train_freq\" : trial.suggest_categorical(\"train_freq\", [4, 8, 16]),\n",
    "        \"gradient_steps\" : trial.suggest_int(\"gradient_steps\", 1, 8),\n",
    "        \"exploration_final_eps\" : trial.suggest_uniform(\"exploration_final_eps\", 0.01, 0.09),\n",
    "        \"exploration_fraction\" : trial.suggest_uniform(\"exploration_fraction\", 0.1, 0.5)\n",
    "    }\n",
    "    env = sf.CreateEnv( 'L4_Ryu_Guile', 1, kLogDir, 6 )\n",
    "    model = QRDQN(\"MlpPolicy\", env, verbose=0, tensorboard_log=kLogDir, **model_params )\n",
    "    model.learn(total_timesteps=kLearnTimesteps)\n",
    "    mean_reward, _ = evaluate_policy(model, env)\n",
    "    env.close()\n",
    "    return mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d25ab-2d1b-4e17-aa3b-562f9691117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d390f39-4e89-4e5d-b74c-c51c9be7360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 16:55:31,917]\u001b[0m A new study created in memory with name: no-name-fa7637e3-3a96-4e5d-81f9-f2e727dbaa09\u001b[0m\n",
      "2023-02-05 16:55:34.627069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 16:55:34.713129: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-05 16:55:34.735391: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay\n",
      "\u001b[32m[I 2023-02-05 17:06:45,881]\u001b[0m Trial 0 finished with value: -277.0 and parameters: {'n_steps': 71, 'gamma': 0.8682550924411929, 'learning_rate': 0.0009954995292206005, 'ent_coef': 0.0035141525456695655, 'vf_coef': 0.3065955092708599, 'max_grad_norm': 0.9188807493400504}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 17:17:53,651]\u001b[0m Trial 1 finished with value: -277.0 and parameters: {'n_steps': 37, 'gamma': 0.825949279052231, 'learning_rate': 0.00018126957402708237, 'ent_coef': 0.026205891159260933, 'vf_coef': 0.07094730548848872, 'max_grad_norm': 0.73434157103834}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 17:29:14,441]\u001b[0m Trial 2 finished with value: -277.0 and parameters: {'n_steps': 41, 'gamma': 0.9711397534011723, 'learning_rate': 0.0005332547537069047, 'ent_coef': 0.06048140650786319, 'vf_coef': 0.11427072091056044, 'max_grad_norm': 0.6042442823235031}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 17:40:33,855]\u001b[0m Trial 3 finished with value: -283.0 and parameters: {'n_steps': 75, 'gamma': 0.9869200399364253, 'learning_rate': 0.0002084606369309837, 'ent_coef': 0.09463131967722073, 'vf_coef': 0.21673113028781205, 'max_grad_norm': 0.9503866266593685}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 17:51:45,733]\u001b[0m Trial 4 finished with value: -277.0 and parameters: {'n_steps': 52, 'gamma': 0.9475039776377913, 'learning_rate': 0.000882048020886462, 'ent_coef': 0.06661893931378299, 'vf_coef': 0.2870435737196044, 'max_grad_norm': 0.42413256530962873}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 18:03:08,487]\u001b[0m Trial 5 finished with value: -277.0 and parameters: {'n_steps': 107, 'gamma': 0.9557808622955312, 'learning_rate': 0.0006780755761352969, 'ent_coef': 0.07994339173344533, 'vf_coef': 0.4076756502309772, 'max_grad_norm': 0.2579315808704817}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 18:14:25,438]\u001b[0m Trial 6 finished with value: -277.0 and parameters: {'n_steps': 89, 'gamma': 0.9901265980742897, 'learning_rate': 0.00033420306475963503, 'ent_coef': 0.027152752619236293, 'vf_coef': 0.47537772424795083, 'max_grad_norm': 0.2998778312441829}. Best is trial 0 with value: -277.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 18:25:59,231]\u001b[0m Trial 7 finished with value: -259.0 and parameters: {'n_steps': 16, 'gamma': 0.9579762962277241, 'learning_rate': 0.0003808610157220845, 'ent_coef': 0.019449138861664238, 'vf_coef': 0.10761044426384099, 'max_grad_norm': 0.46074928279973615}. Best is trial 7 with value: -259.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 18:37:35,194]\u001b[0m Trial 8 finished with value: -227.0 and parameters: {'n_steps': 84, 'gamma': 0.8865249847446781, 'learning_rate': 0.0004846116723321004, 'ent_coef': 0.00620095091969879, 'vf_coef': 0.4494704054968704, 'max_grad_norm': 0.6366064355857866}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 18:49:02,784]\u001b[0m Trial 9 finished with value: -277.0 and parameters: {'n_steps': 94, 'gamma': 0.9391582755506347, 'learning_rate': 0.0002283936675662268, 'ent_coef': 0.011681687362180577, 'vf_coef': 0.43613923332316074, 'max_grad_norm': 0.5873564488479006}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:00:35,098]\u001b[0m Trial 10 finished with value: -277.0 and parameters: {'n_steps': 123, 'gamma': 0.8895930580587412, 'learning_rate': 0.0006319439075137055, 'ent_coef': 0.04268765026640949, 'vf_coef': 0.36002181048700765, 'max_grad_norm': 0.12057822103463339}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:12:09,880]\u001b[0m Trial 11 finished with value: -277.0 and parameters: {'n_steps': 17, 'gamma': 0.9136294588245829, 'learning_rate': 0.0003829911902871831, 'ent_coef': 0.022783873773740915, 'vf_coef': 0.17848712542422673, 'max_grad_norm': 0.7342096161266152}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:23:40,498]\u001b[0m Trial 12 finished with value: -277.0 and parameters: {'n_steps': 16, 'gamma': 0.8489139367113385, 'learning_rate': 2.0843176283551494e-05, 'ent_coef': 0.004534480294394993, 'vf_coef': 0.04663067868514634, 'max_grad_norm': 0.4439708012079818}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:34:23,140]\u001b[0m Trial 13 finished with value: -266.0 and parameters: {'n_steps': 67, 'gamma': 0.9116301097645738, 'learning_rate': 0.00047070538651366236, 'ent_coef': 0.04341999991759534, 'vf_coef': 0.16966749266883707, 'max_grad_norm': 0.7487068232340703}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:45:03,984]\u001b[0m Trial 14 finished with value: -266.0 and parameters: {'n_steps': 55, 'gamma': 0.8873765762097264, 'learning_rate': 0.0007059142366514662, 'ent_coef': 0.017838896744855018, 'vf_coef': 0.015302663991014293, 'max_grad_norm': 0.4575531509473627}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 19:55:35,523]\u001b[0m Trial 15 finished with value: -277.0 and parameters: {'n_steps': 89, 'gamma': 0.8531813426469661, 'learning_rate': 0.0005162700689771947, 'ent_coef': 0.03423142993451282, 'vf_coef': 0.3480768801882459, 'max_grad_norm': 0.6368621214635627}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 20:06:14,199]\u001b[0m Trial 16 finished with value: -266.0 and parameters: {'n_steps': 111, 'gamma': 0.8082928833992173, 'learning_rate': 0.0003603396377270771, 'ent_coef': 0.003291493023362242, 'vf_coef': 0.1234663253711992, 'max_grad_norm': 0.33263560957359706}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 20:16:49,649]\u001b[0m Trial 17 finished with value: -251.0 and parameters: {'n_steps': 31, 'gamma': 0.9312984975496418, 'learning_rate': 0.0007849287310291883, 'ent_coef': 0.0548265715221351, 'vf_coef': 0.23376704796014164, 'max_grad_norm': 0.8603831081470956}. Best is trial 8 with value: -227.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 20:27:39,130]\u001b[0m Trial 18 finished with value: -134.63999999999996 and parameters: {'n_steps': 32, 'gamma': 0.9219513462075898, 'learning_rate': 0.0008247862823389501, 'ent_coef': 0.05764738718774189, 'vf_coef': 0.24613796230823268, 'max_grad_norm': 0.8379923618752754}. Best is trial 18 with value: -134.63999999999996.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 20:38:50,523]\u001b[0m Trial 19 finished with value: -277.0 and parameters: {'n_steps': 54, 'gamma': 0.9181436315123109, 'learning_rate': 0.0009176847424007998, 'ent_coef': 0.07284767465952499, 'vf_coef': 0.4817967182394267, 'max_grad_norm': 0.8293427199198512}. Best is trial 18 with value: -134.63999999999996.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_steps': 32,\n",
       " 'gamma': 0.9219513462075898,\n",
       " 'learning_rate': 0.0008247862823389501,\n",
       " 'ent_coef': 0.05764738718774189,\n",
       " 'vf_coef': 0.24613796230823268,\n",
       " 'max_grad_norm': 0.8379923618752754}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_A2C_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_a2c_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14df9ba7-7817-4373-84fd-a08635f3fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('A2C.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a012f0-4416-4f74-aad2-102cb6f2ce95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f03edb27-ea8c-41da-8444-fef7ec7bc8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-05 20:38:50,595]\u001b[0m A new study created in memory with name: no-name-a7d80cb5-5610-4758-a178-a2ae6062d4e7\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 20:50:33,258]\u001b[0m Trial 0 finished with value: -194.0 and parameters: {'batch_size': 128, 'n_steps': 4096, 'gamma': 0.8988542729977321, 'learning_rate': 3.9329135162204456e-05, 'clip_range': 0.24155717161264847, 'gae_lambda': 0.8439854700634416}. Best is trial 0 with value: -194.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 21:03:37,564]\u001b[0m Trial 1 finished with value: -107.88 and parameters: {'batch_size': 64, 'n_steps': 128, 'gamma': 0.9609610335365972, 'learning_rate': 0.0004045201186876571, 'clip_range': 0.3525024480214578, 'gae_lambda': 0.9553970353438237}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 21:53:23,480]\u001b[0m Trial 2 finished with value: -254.0 and parameters: {'batch_size': 8, 'n_steps': 1024, 'gamma': 0.8020970062275904, 'learning_rate': 0.00011946742810732661, 'clip_range': 0.18165373674237656, 'gae_lambda': 0.8497358896158252}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 22:06:22,011]\u001b[0m Trial 3 finished with value: -277.0 and parameters: {'batch_size': 64, 'n_steps': 128, 'gamma': 0.9425455158904348, 'learning_rate': 1.4994199544469355e-05, 'clip_range': 0.21454189778414826, 'gae_lambda': 0.9862959808427273}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 22:20:11,532]\u001b[0m Trial 4 finished with value: -249.0 and parameters: {'batch_size': 32, 'n_steps': 256, 'gamma': 0.9889999026929641, 'learning_rate': 0.0002651086015496477, 'clip_range': 0.3892206731721206, 'gae_lambda': 0.9004047109335047}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 22:37:13,987]\u001b[0m Trial 5 finished with value: -180.44 and parameters: {'batch_size': 16, 'n_steps': 256, 'gamma': 0.869808842981579, 'learning_rate': 0.0009576385385445446, 'clip_range': 0.2869157517142462, 'gae_lambda': 0.899457903213966}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 23:01:02,268]\u001b[0m Trial 6 finished with value: -261.0 and parameters: {'batch_size': 8, 'n_steps': 256, 'gamma': 0.9579271832232972, 'learning_rate': 4.4032767195701846e-05, 'clip_range': 0.3042329826227823, 'gae_lambda': 0.8413491265719009}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 256`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=256 and n_envs=1)\n",
      "\u001b[32m[I 2023-02-05 23:12:39,305]\u001b[0m Trial 7 finished with value: -277.0 and parameters: {'batch_size': 512, 'n_steps': 256, 'gamma': 0.9086846498555893, 'learning_rate': 0.0001732867569273032, 'clip_range': 0.29208679549335825, 'gae_lambda': 0.9825039736964365}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 23:23:17,092]\u001b[0m Trial 8 finished with value: -277.0 and parameters: {'batch_size': 512, 'n_steps': 1024, 'gamma': 0.800119304922099, 'learning_rate': 1.193153574621144e-05, 'clip_range': 0.14268123429750854, 'gae_lambda': 0.8426722451416289}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 23:34:47,591]\u001b[0m Trial 9 finished with value: -194.0 and parameters: {'batch_size': 256, 'n_steps': 2048, 'gamma': 0.9481893064859006, 'learning_rate': 6.358871543453124e-05, 'clip_range': 0.31474548275826597, 'gae_lambda': 0.8764051053990949}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-05 23:48:08,070]\u001b[0m Trial 10 finished with value: -277.0 and parameters: {'batch_size': 64, 'n_steps': 128, 'gamma': 0.849522293489016, 'learning_rate': 0.0005662807320898501, 'clip_range': 0.38664612021310324, 'gae_lambda': 0.9404003737928809}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 00:05:40,020]\u001b[0m Trial 11 finished with value: -117.0 and parameters: {'batch_size': 16, 'n_steps': 64, 'gamma': 0.8575997499491763, 'learning_rate': 0.0007570332317933941, 'clip_range': 0.34441500839335926, 'gae_lambda': 0.931784449367143}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 00:23:00,637]\u001b[0m Trial 12 finished with value: -247.80000000000004 and parameters: {'batch_size': 16, 'n_steps': 64, 'gamma': 0.845312425091054, 'learning_rate': 0.0003842072119253974, 'clip_range': 0.35224481744535, 'gae_lambda': 0.9440809061214206}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 00:39:09,777]\u001b[0m Trial 13 finished with value: -277.0 and parameters: {'batch_size': 16, 'n_steps': 512, 'gamma': 0.997769863402217, 'learning_rate': 0.0009673338887931606, 'clip_range': 0.3482614286876182, 'gae_lambda': 0.9391931382554839}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 00:53:04,291]\u001b[0m Trial 14 finished with value: -284.0 and parameters: {'batch_size': 64, 'n_steps': 64, 'gamma': 0.8704506054218368, 'learning_rate': 0.0004578055915612445, 'clip_range': 0.3402084692210665, 'gae_lambda': 0.9606985990943985}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 01:07:54,715]\u001b[0m Trial 15 finished with value: -217.0 and parameters: {'batch_size': 32, 'n_steps': 8192, 'gamma': 0.921157765675503, 'learning_rate': 0.0002644844139184978, 'clip_range': 0.10148091400314471, 'gae_lambda': 0.809572974884372}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 128, but because the `RolloutBuffer` is of size `n_steps * n_envs = 64`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=64 and n_envs=1)\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-06 01:21:38,442]\u001b[0m Trial 16 finished with value: -233.0 and parameters: {'batch_size': 128, 'n_steps': 64, 'gamma': 0.8286731430180934, 'learning_rate': 0.0005959190227596143, 'clip_range': 0.26003128032374384, 'gae_lambda': 0.9182158939380008}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/ppo/ppo.py:145: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 128`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 128\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=128 and n_envs=1)\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-06 01:34:14,755]\u001b[0m Trial 17 finished with value: -281.80000000000007 and parameters: {'batch_size': 256, 'n_steps': 128, 'gamma': 0.9754012189075097, 'learning_rate': 0.00018017398808745362, 'clip_range': 0.39395070725282094, 'gae_lambda': 0.9678913445720962}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 01:45:48,792]\u001b[0m Trial 18 finished with value: -187.0 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.8834291593586768, 'learning_rate': 0.0007354871007163698, 'clip_range': 0.3392222112382787, 'gae_lambda': 0.9211440106433977}. Best is trial 1 with value: -107.88.\u001b[0m\n",
      "\u001b[32m[I 2023-02-06 02:03:54,516]\u001b[0m Trial 19 finished with value: -142.0 and parameters: {'batch_size': 16, 'n_steps': 4096, 'gamma': 0.9269637407803536, 'learning_rate': 0.00031845757775641803, 'clip_range': 0.26056763103472114, 'gae_lambda': 0.8783168347745636}. Best is trial 1 with value: -107.88.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'n_steps': 128,\n",
       " 'gamma': 0.9609610335365972,\n",
       " 'learning_rate': 0.0004045201186876571,\n",
       " 'clip_range': 0.3525024480214578,\n",
       " 'gae_lambda': 0.9553970353438237}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_PPO_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_ppo_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65dd6ce-1430-42c7-a869-a057039e9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PPO.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac3ed76-d748-47e7-a26e-4db7a7b77809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a25e56-d6dd-4455-9526-e0f53e60395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-07 18:01:24,200]\u001b[0m A new study created in memory with name: no-name-fdb8bbe9-4b96-4285-9dd5-33fb2ff93bdf\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 31.33GB\n",
      "  warnings.warn(\n",
      "2023-02-07 18:01:25.480777: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 18:01:25.556269: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-07 18:01:25.578741: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay\n",
      "\u001b[32m[I 2023-02-07 18:10:51,796]\u001b[0m Trial 0 finished with value: -241.0 and parameters: {'learning_rate': 0.00042122824562271894, 'learning_starts': 50000, 'batch_size': 8, 'gamma': 0.8776890932662562, 'train_freq': 4, 'gradient_steps': 1, 'exploration_final_eps': 0.06986319850848853, 'exploration_fraction': 0.2193160874204005}. Best is trial 0 with value: -241.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.49GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 18:27:06,074]\u001b[0m Trial 1 finished with value: -241.0 and parameters: {'learning_rate': 0.0001775457459044453, 'learning_starts': 10000, 'batch_size': 128, 'gamma': 0.9661086681430504, 'train_freq': 8, 'gradient_steps': 7, 'exploration_final_eps': 0.030119753278298064, 'exploration_fraction': 0.24045091768132645}. Best is trial 0 with value: -241.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.46GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 18:36:32,453]\u001b[0m Trial 2 finished with value: -242.0 and parameters: {'learning_rate': 0.0001883313660907413, 'learning_starts': 50000, 'batch_size': 8, 'gamma': 0.9299741925203742, 'train_freq': 16, 'gradient_steps': 4, 'exploration_final_eps': 0.08621047527802081, 'exploration_fraction': 0.2896368858403762}. Best is trial 0 with value: -241.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.45GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 18:50:29,861]\u001b[0m Trial 3 finished with value: -183.0 and parameters: {'learning_rate': 1.9230444388745563e-05, 'learning_starts': 10000, 'batch_size': 512, 'gamma': 0.8376641230637156, 'train_freq': 16, 'gradient_steps': 4, 'exploration_final_eps': 0.07825420853904093, 'exploration_fraction': 0.19160368865582306}. Best is trial 3 with value: -183.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.43GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 19:02:22,959]\u001b[0m Trial 4 finished with value: -241.0 and parameters: {'learning_rate': 4.444914542128721e-05, 'learning_starts': 20000, 'batch_size': 16, 'gamma': 0.9572707595605822, 'train_freq': 8, 'gradient_steps': 4, 'exploration_final_eps': 0.055996670519504424, 'exploration_fraction': 0.29604076060162854}. Best is trial 3 with value: -183.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 19:15:31,792]\u001b[0m Trial 5 finished with value: -250.0 and parameters: {'learning_rate': 0.00011816288100184712, 'learning_starts': 1000, 'batch_size': 128, 'gamma': 0.9767233972626855, 'train_freq': 8, 'gradient_steps': 4, 'exploration_final_eps': 0.07771856699015944, 'exploration_fraction': 0.13256446165064528}. Best is trial 3 with value: -183.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.44GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 19:27:26,208]\u001b[0m Trial 6 finished with value: -106.12 and parameters: {'learning_rate': 5.8778983576095745e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.8725607763842587, 'train_freq': 8, 'gradient_steps': 1, 'exploration_final_eps': 0.06999189354271829, 'exploration_fraction': 0.34412108119160434}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.42GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 19:41:01,262]\u001b[0m Trial 7 finished with value: -271.0 and parameters: {'learning_rate': 0.0002612307085325922, 'learning_starts': 20000, 'batch_size': 64, 'gamma': 0.9339341050397322, 'train_freq': 4, 'gradient_steps': 4, 'exploration_final_eps': 0.03416901945693227, 'exploration_fraction': 0.22141599729218103}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 19:52:24,350]\u001b[0m Trial 8 finished with value: -277.0 and parameters: {'learning_rate': 0.0003151910249095721, 'learning_starts': 50000, 'batch_size': 128, 'gamma': 0.9505885599058794, 'train_freq': 8, 'gradient_steps': 5, 'exploration_final_eps': 0.044350930505659414, 'exploration_fraction': 0.2776376699178321}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 20:02:09,199]\u001b[0m Trial 9 finished with value: -245.0 and parameters: {'learning_rate': 4.2193992216425295e-05, 'learning_starts': 50000, 'batch_size': 8, 'gamma': 0.9924651949876924, 'train_freq': 8, 'gradient_steps': 3, 'exploration_final_eps': 0.01296329918712523, 'exploration_fraction': 0.41277361655879663}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.41GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 20:15:11,916]\u001b[0m Trial 10 finished with value: -108.68000000000002 and parameters: {'learning_rate': 1.0463903977308527e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.8179577050411388, 'train_freq': 4, 'gradient_steps': 1, 'exploration_final_eps': 0.0625882850839003, 'exploration_fraction': 0.4011433093424214}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 20:28:38,549]\u001b[0m Trial 11 finished with value: -253.0 and parameters: {'learning_rate': 1.08901442289986e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.805807430554669, 'train_freq': 4, 'gradient_steps': 1, 'exploration_final_eps': 0.06086543234974503, 'exploration_fraction': 0.41066650278329636}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.40GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 20:46:37,564]\u001b[0m Trial 12 finished with value: -281.80000000000007 and parameters: {'learning_rate': 4.9217793302205203e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.8685302797544812, 'train_freq': 4, 'gradient_steps': 2, 'exploration_final_eps': 0.06836502374677049, 'exploration_fraction': 0.49734928867368117}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 21:00:14,823]\u001b[0m Trial 13 finished with value: -166.0 and parameters: {'learning_rate': 0.0006917798387899947, 'learning_starts': 30000, 'batch_size': 256, 'gamma': 0.8083450066313337, 'train_freq': 4, 'gradient_steps': 2, 'exploration_final_eps': 0.04929995056782378, 'exploration_fraction': 0.3754697953894254}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 21:11:19,078]\u001b[0m Trial 14 finished with value: -217.0 and parameters: {'learning_rate': 1.0257119560233166e-05, 'learning_starts': 40000, 'batch_size': 32, 'gamma': 0.8488132806342948, 'train_freq': 16, 'gradient_steps': 6, 'exploration_final_eps': 0.06436534007668417, 'exploration_fraction': 0.37094088069721}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 21:29:28,882]\u001b[0m Trial 15 finished with value: -253.0 and parameters: {'learning_rate': 2.510447695932661e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.902279320599426, 'train_freq': 4, 'gradient_steps': 2, 'exploration_final_eps': 0.0890246902129295, 'exploration_fraction': 0.4756236833510694}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 21:58:17,656]\u001b[0m Trial 16 finished with value: -229.0 and parameters: {'learning_rate': 9.126527267463472e-05, 'learning_starts': 30000, 'batch_size': 512, 'gamma': 0.8392124183310864, 'train_freq': 8, 'gradient_steps': 8, 'exploration_final_eps': 0.04184982486540596, 'exploration_fraction': 0.3430210424844977}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 28.03GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-07 22:09:37,474]\u001b[0m Trial 17 finished with value: -261.0 and parameters: {'learning_rate': 2.070975763135872e-05, 'learning_starts': 1000, 'batch_size': 32, 'gamma': 0.8936248422912305, 'train_freq': 4, 'gradient_steps': 1, 'exploration_final_eps': 0.07670956164890795, 'exploration_fraction': 0.43842848613755764}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 22:20:28,353]\u001b[0m Trial 18 finished with value: -251.6 and parameters: {'learning_rate': 7.760626145537864e-05, 'learning_starts': 40000, 'batch_size': 64, 'gamma': 0.8254044435736818, 'train_freq': 8, 'gradient_steps': 2, 'exploration_final_eps': 0.055381684833838596, 'exploration_fraction': 0.334345893033023}. Best is trial 6 with value: -106.12.\u001b[0m\n",
      "\u001b[32m[I 2023-02-07 22:31:30,504]\u001b[0m Trial 19 finished with value: -271.0 and parameters: {'learning_rate': 0.0009971437329946314, 'learning_starts': 30000, 'batch_size': 256, 'gamma': 0.8674844371630571, 'train_freq': 16, 'gradient_steps': 3, 'exploration_final_eps': 0.013232346778162152, 'exploration_fraction': 0.4394223528333859}. Best is trial 6 with value: -106.12.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 5.8778983576095745e-05,\n",
       " 'learning_starts': 30000,\n",
       " 'batch_size': 512,\n",
       " 'gamma': 0.8725607763842587,\n",
       " 'train_freq': 8,\n",
       " 'gradient_steps': 1,\n",
       " 'exploration_final_eps': 0.06999189354271829,\n",
       " 'exploration_fraction': 0.34412108119160434}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_QRDQN_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_qrdqn_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3882f5e4-6c06-4473-b21c-763cda213cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('QRDQN.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306fc5c7-ba27-4318-a646-a16db439ea32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026d0a6-c64a-4183-81e2-61896d475b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3cdb05d-8882-4341-8610-ae5c5bdf7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-08 00:04:48,969]\u001b[0m A new study created in memory with name: no-name-c5c8f0d9-882a-4854-9da7-70f104abb6f2\u001b[0m\n",
      "2023-02-08 00:04:51.071391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-08 00:04:51.237972: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-08 00:04:51.283024: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay\n",
      "\u001b[32m[I 2023-02-08 00:39:08,403]\u001b[0m Trial 0 finished with value: -240.0 and parameters: {'batch_size': 256, 'n_steps': 128, 'gamma': 0.8736767971298365, 'learning_rate': 6.372036279085897e-05, 'clip_range': 0.21664497912708344, 'gae_lambda': 0.8288208028552041, 'ent_coef': 0.06624706093153768, 'vf_coef': 0.14151116971526476, 'max_grad_norm': 0.950660014966343}. Best is trial 0 with value: -240.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 01:13:48,439]\u001b[0m Trial 1 finished with value: -277.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.8404554095717839, 'learning_rate': 0.0009679034054434513, 'clip_range': 0.36795780890184704, 'gae_lambda': 0.8349808579092568, 'ent_coef': 0.030284264041644946, 'vf_coef': 0.4626640073500351, 'max_grad_norm': 0.8940796161245771}. Best is trial 0 with value: -240.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 01:50:02,308]\u001b[0m Trial 2 finished with value: -242.0 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.9225595376063302, 'learning_rate': 0.000790549618633179, 'clip_range': 0.2974374497568556, 'gae_lambda': 0.8989833993011428, 'ent_coef': 0.09993309885902889, 'vf_coef': 0.3518756677541906, 'max_grad_norm': 0.19011035397393738}. Best is trial 0 with value: -240.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 02:24:06,896]\u001b[0m Trial 3 finished with value: -251.0 and parameters: {'batch_size': 256, 'n_steps': 128, 'gamma': 0.8069855146358659, 'learning_rate': 0.0002314184073235769, 'clip_range': 0.1941651549977468, 'gae_lambda': 0.9626927775251687, 'ent_coef': 0.0367260485271458, 'vf_coef': 0.12377039068600035, 'max_grad_norm': 0.6392907010342036}. Best is trial 0 with value: -240.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 02:58:14,859]\u001b[0m Trial 4 finished with value: -107.96 and parameters: {'batch_size': 256, 'n_steps': 128, 'gamma': 0.9458934963074525, 'learning_rate': 0.0003274472195016304, 'clip_range': 0.15134180114627965, 'gae_lambda': 0.8641173342911478, 'ent_coef': 0.041791368450251554, 'vf_coef': 0.4174156582381447, 'max_grad_norm': 0.5984737727186535}. Best is trial 4 with value: -107.96.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 03:31:52,274]\u001b[0m Trial 5 finished with value: -170.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.9598900188901593, 'learning_rate': 0.0002285179486525406, 'clip_range': 0.2976112233791454, 'gae_lambda': 0.9242497260302744, 'ent_coef': 0.09649186408755935, 'vf_coef': 0.3406852958188303, 'max_grad_norm': 0.4953411674474145}. Best is trial 4 with value: -107.96.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 04:08:51,990]\u001b[0m Trial 6 finished with value: -225.68 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.9711572946389702, 'learning_rate': 0.0009878167056336885, 'clip_range': 0.2755081486009383, 'gae_lambda': 0.8215555211208107, 'ent_coef': 0.060321547987049334, 'vf_coef': 0.4069572005318005, 'max_grad_norm': 0.4835196272364398}. Best is trial 4 with value: -107.96.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 04:41:25,318]\u001b[0m Trial 7 finished with value: -205.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.9541576714018939, 'learning_rate': 0.00033756361647806253, 'clip_range': 0.3822343901202133, 'gae_lambda': 0.911012867086171, 'ent_coef': 0.008906107104151885, 'vf_coef': 0.27218793416793347, 'max_grad_norm': 0.679811948741998}. Best is trial 4 with value: -107.96.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 05:16:10,823]\u001b[0m Trial 8 finished with value: -101.0 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.9560821301100058, 'learning_rate': 0.0009697975901111305, 'clip_range': 0.37281645364831995, 'gae_lambda': 0.9043651572782224, 'ent_coef': 0.00727905612251794, 'vf_coef': 0.49282068512883936, 'max_grad_norm': 0.7994437708612409}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 05:50:40,157]\u001b[0m Trial 9 finished with value: -244.0 and parameters: {'batch_size': 256, 'n_steps': 128, 'gamma': 0.9661219416486995, 'learning_rate': 0.0006142891786604418, 'clip_range': 0.17030367732886612, 'gae_lambda': 0.8742090264127754, 'ent_coef': 0.018268518407619005, 'vf_coef': 0.3624864978121847, 'max_grad_norm': 0.8393041569970988}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 06:24:56,724]\u001b[0m Trial 10 finished with value: -277.0 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.8969511252054192, 'learning_rate': 0.0006414740707743484, 'clip_range': 0.3325196552730583, 'gae_lambda': 0.9861578034614118, 'ent_coef': 0.002299274847897166, 'vf_coef': 0.046041811977180824, 'max_grad_norm': 0.23805270526476835}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 07:15:40,715]\u001b[0m Trial 11 finished with value: -141.32 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9178760273503095, 'learning_rate': 0.0004495459439528294, 'clip_range': 0.10014457884067346, 'gae_lambda': 0.8719205897446171, 'ent_coef': 0.04401745055216985, 'vf_coef': 0.4893224079288747, 'max_grad_norm': 0.7479425429968694}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 08:07:52,593]\u001b[0m Trial 12 finished with value: -277.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9992576530073011, 'learning_rate': 0.0007932079707212837, 'clip_range': 0.12647378069453044, 'gae_lambda': 0.8633244745305634, 'ent_coef': 0.07784154590186304, 'vf_coef': 0.4869241038106007, 'max_grad_norm': 0.3417015071070597}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 09:00:24,436]\u001b[0m Trial 13 finished with value: -243.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9992541519406523, 'learning_rate': 0.00046157000265551954, 'clip_range': 0.2313387490944779, 'gae_lambda': 0.9470856870424685, 'ent_coef': 0.02467326526658345, 'vf_coef': 0.24396527399303178, 'max_grad_norm': 0.58254818472741}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 09:53:08,169]\u001b[0m Trial 14 finished with value: -266.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9333342632367522, 'learning_rate': 4.389684756603361e-05, 'clip_range': 0.16396298015596908, 'gae_lambda': 0.8021325373465261, 'ent_coef': 0.05157129491001095, 'vf_coef': 0.42091218507013933, 'max_grad_norm': 0.7930330226586001}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 10:25:56,540]\u001b[0m Trial 15 finished with value: -198.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.9045893918482503, 'learning_rate': 0.00031169566016109546, 'clip_range': 0.3316719352963914, 'gae_lambda': 0.9290488689644943, 'ent_coef': 0.01262705115886728, 'vf_coef': 0.26351414544604457, 'max_grad_norm': 0.38438509208413996}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 11:00:53,704]\u001b[0m Trial 16 finished with value: -277.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.8751931038920138, 'learning_rate': 0.0006633377136016622, 'clip_range': 0.3996264832777418, 'gae_lambda': 0.8560091795929049, 'ent_coef': 0.07729723717713674, 'vf_coef': 0.4059288307780873, 'max_grad_norm': 0.6942691365555402}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 11:52:33,561]\u001b[0m Trial 17 finished with value: -153.92000000000002 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9433573088623971, 'learning_rate': 0.0008292020790859483, 'clip_range': 0.2584068564142503, 'gae_lambda': 0.8873172527877171, 'ent_coef': 0.04002584412263224, 'vf_coef': 0.4441346607660881, 'max_grad_norm': 0.9982324603289088}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 12:42:09,513]\u001b[0m Trial 18 finished with value: -181.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9823719872038809, 'learning_rate': 0.0001638298935910553, 'clip_range': 0.15039380336139135, 'gae_lambda': 0.8483540704699879, 'ent_coef': 0.028015776276222867, 'vf_coef': 0.30383101177782, 'max_grad_norm': 0.5712533613254558}. Best is trial 8 with value: -101.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-08 13:14:14,161]\u001b[0m Trial 19 finished with value: -277.0 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.9428840121059527, 'learning_rate': 0.0005357237039659581, 'clip_range': 0.34617196514446463, 'gae_lambda': 0.8990034800860217, 'ent_coef': 0.0012536926722870462, 'vf_coef': 0.21255654490553397, 'max_grad_norm': 0.4368126994720407}. Best is trial 8 with value: -101.0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'n_steps': 256,\n",
       " 'gamma': 0.9560821301100058,\n",
       " 'learning_rate': 0.0009697975901111305,\n",
       " 'clip_range': 0.37281645364831995,\n",
       " 'gae_lambda': 0.9043651572782224,\n",
       " 'ent_coef': 0.00727905612251794,\n",
       " 'vf_coef': 0.49282068512883936,\n",
       " 'max_grad_norm': 0.7994437708612409}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_RPPO_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_rppo_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "210cc885-7020-4a35-a403-d068cf85dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RPPO.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc431f-585c-4572-bef8-10f5518148e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045bfac-7a92-487e-8cad-e7dcb1aa7e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9f36c-7883-42b4-8d25-5565dbbe717f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57d68620-33ee-4150-a75b-539dc0a26d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-12 13:44:05,172]\u001b[0m A new study created in memory with name: no-name-641490f8-88cb-45e0-83a4-3e8bcfc3afa7\u001b[0m\n",
      "/tmp/ipykernel_5855/948129050.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "2023-02-12 13:44:06.200701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-12 13:44:06.287236: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-12 13:44:06.313427: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay\n",
      "\u001b[32m[I 2023-02-12 14:01:51,072]\u001b[0m Trial 0 finished with value: -208.76 and parameters: {'batch_size': 8, 'n_steps': 64, 'gamma': 0.8406026006497601, 'learning_rate': 0.00019007102674124457, 'gae_lambda': 0.8922913779274315, 'n_critic_updates': 5, 'cg_max_steps': 20, 'target_kl': 0.1}. Best is trial 0 with value: -208.76.\u001b[0m\n",
      "/tmp/ipykernel_5855/948129050.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-02-12 14:14:52,687]\u001b[0m Trial 1 finished with value: -85.0 and parameters: {'batch_size': 128, 'n_steps': 8192, 'gamma': 0.8817303094122192, 'learning_rate': 4.526484548452555e-05, 'gae_lambda': 0.8093408480847264, 'n_critic_updates': 10, 'cg_max_steps': 30, 'target_kl': 0.03}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/sb3_contrib/trpo/trpo.py:144: UserWarning: You have specified a mini-batch size of 256, but because the `RolloutBuffer` is of size `n_steps * n_envs = 64`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 64\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=64 and n_envs=1)\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 14:32:32,726]\u001b[0m Trial 2 finished with value: -244.0 and parameters: {'batch_size': 256, 'n_steps': 64, 'gamma': 0.9834725430901218, 'learning_rate': 0.00014665665685441927, 'gae_lambda': 0.9531899974363056, 'n_critic_updates': 30, 'cg_max_steps': 25, 'target_kl': 0.05}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 14:45:57,559]\u001b[0m Trial 3 finished with value: -231.0 and parameters: {'batch_size': 64, 'n_steps': 512, 'gamma': 0.8822920691530907, 'learning_rate': 3.703577054194853e-05, 'gae_lambda': 0.8001325558634597, 'n_critic_updates': 25, 'cg_max_steps': 20, 'target_kl': 0.001}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 14:59:16,832]\u001b[0m Trial 4 finished with value: -253.0 and parameters: {'batch_size': 128, 'n_steps': 256, 'gamma': 0.8060087934553517, 'learning_rate': 9.047345328418856e-05, 'gae_lambda': 0.8494422546433896, 'n_critic_updates': 25, 'cg_max_steps': 30, 'target_kl': 0.1}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 15:13:52,818]\u001b[0m Trial 5 finished with value: -179.8 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.9313003067826483, 'learning_rate': 0.00019163031223547443, 'gae_lambda': 0.8525982269761896, 'n_critic_updates': 25, 'cg_max_steps': 25, 'target_kl': 0.001}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/sb3_contrib/trpo/trpo.py:144: UserWarning: You have specified a mini-batch size of 512, but because the `RolloutBuffer` is of size `n_steps * n_envs = 256`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 256\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=256 and n_envs=1)\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 15:26:05,392]\u001b[0m Trial 6 finished with value: -250.0 and parameters: {'batch_size': 512, 'n_steps': 256, 'gamma': 0.8929974861144359, 'learning_rate': 0.00010498005747988111, 'gae_lambda': 0.8713058604154118, 'n_critic_updates': 25, 'cg_max_steps': 5, 'target_kl': 0.03}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 15:38:30,335]\u001b[0m Trial 7 finished with value: -233.0 and parameters: {'batch_size': 128, 'n_steps': 1024, 'gamma': 0.9703841194971664, 'learning_rate': 0.00016116056757720546, 'gae_lambda': 0.9302019990330205, 'n_critic_updates': 20, 'cg_max_steps': 30, 'target_kl': 0.001}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 15:50:30,351]\u001b[0m Trial 8 finished with value: -152.0 and parameters: {'batch_size': 512, 'n_steps': 2048, 'gamma': 0.8471264773661631, 'learning_rate': 1.8064230631551815e-05, 'gae_lambda': 0.8237129003111618, 'n_critic_updates': 10, 'cg_max_steps': 30, 'target_kl': 0.1}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 16:03:43,462]\u001b[0m Trial 9 finished with value: -117.52000000000001 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.8268278989359179, 'learning_rate': 1.6995714745047306e-05, 'gae_lambda': 0.8224652640197502, 'n_critic_updates': 20, 'cg_max_steps': 20, 'target_kl': 0.1}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 16:19:02,272]\u001b[0m Trial 10 finished with value: -277.0 and parameters: {'batch_size': 16, 'n_steps': 8192, 'gamma': 0.9262167052799588, 'learning_rate': 0.0009777832109011037, 'gae_lambda': 0.9876486269286153, 'n_critic_updates': 10, 'cg_max_steps': 10, 'target_kl': 0.03}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 16:33:25,739]\u001b[0m Trial 11 finished with value: -248.0 and parameters: {'batch_size': 64, 'n_steps': 8192, 'gamma': 0.8015849633209293, 'learning_rate': 1.5882798825199295e-05, 'gae_lambda': 0.8012549546446063, 'n_critic_updates': 20, 'cg_max_steps': 20, 'target_kl': 0.02}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 16:46:56,835]\u001b[0m Trial 12 finished with value: -206.0 and parameters: {'batch_size': 32, 'n_steps': 4096, 'gamma': 0.8505055609239304, 'learning_rate': 3.893332858150804e-05, 'gae_lambda': 0.8321762315853529, 'n_critic_updates': 10, 'cg_max_steps': 5, 'target_kl': 0.01}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 17:01:30,845]\u001b[0m Trial 13 finished with value: -244.0 and parameters: {'batch_size': 64, 'n_steps': 8192, 'gamma': 0.8580399484259825, 'learning_rate': 1.0348557398758167e-05, 'gae_lambda': 0.8862780961299398, 'n_critic_updates': 20, 'cg_max_steps': 10, 'target_kl': 0.005}. Best is trial 1 with value: -85.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 17:15:04,465]\u001b[0m Trial 14 finished with value: 128.2 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.9203938773776468, 'learning_rate': 3.498635674066087e-05, 'gae_lambda': 0.8277127959450231, 'n_critic_updates': 30, 'cg_max_steps': 20, 'target_kl': 0.03}. Best is trial 14 with value: 128.2.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 17:29:00,514]\u001b[0m Trial 15 finished with value: -173.0 and parameters: {'batch_size': 256, 'n_steps': 4096, 'gamma': 0.9307221510157835, 'learning_rate': 4.5875914559543166e-05, 'gae_lambda': 0.856229747416245, 'n_critic_updates': 30, 'cg_max_steps': 30, 'target_kl': 0.03}. Best is trial 14 with value: 128.2.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 17:42:08,030]\u001b[0m Trial 16 finished with value: -233.0 and parameters: {'batch_size': 256, 'n_steps': 1024, 'gamma': 0.9536759544610341, 'learning_rate': 6.0688131342479846e-05, 'gae_lambda': 0.9292291617631563, 'n_critic_updates': 30, 'cg_max_steps': 30, 'target_kl': 0.03}. Best is trial 14 with value: 128.2.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 17:58:05,634]\u001b[0m Trial 17 finished with value: -102.0 and parameters: {'batch_size': 8, 'n_steps': 128, 'gamma': 0.9050256881159642, 'learning_rate': 0.000429970339166918, 'gae_lambda': 0.8311699703231324, 'n_critic_updates': 5, 'cg_max_steps': 20, 'target_kl': 0.03}. Best is trial 14 with value: 128.2.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 18:18:20,568]\u001b[0m Trial 18 finished with value: -249.0 and parameters: {'batch_size': 16, 'n_steps': 512, 'gamma': 0.8684334166471411, 'learning_rate': 2.4663911602582948e-05, 'gae_lambda': 0.8118458144455679, 'n_critic_updates': 30, 'cg_max_steps': 5, 'target_kl': 0.05}. Best is trial 14 with value: 128.2.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 18:31:29,720]\u001b[0m Trial 19 finished with value: -277.0 and parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.9034416375183382, 'learning_rate': 6.217944116900182e-05, 'gae_lambda': 0.8722862818940209, 'n_critic_updates': 10, 'cg_max_steps': 25, 'target_kl': 0.02}. Best is trial 14 with value: 128.2.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256,\n",
       " 'n_steps': 256,\n",
       " 'gamma': 0.9203938773776468,\n",
       " 'learning_rate': 3.498635674066087e-05,\n",
       " 'gae_lambda': 0.8277127959450231,\n",
       " 'n_critic_updates': 30,\n",
       " 'cg_max_steps': 20,\n",
       " 'target_kl': 0.03}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_TRPO_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_trpo_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f21385e7-f884-4cd5-8270-20dc33a3e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TRPO.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33b233-f616-449d-9580-5d91ee151b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1ae1e-8004-4ddc-ad12-a0200e2c2769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1322069-7733-46ed-b06b-b97b027a28ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-12 21:55:35,941]\u001b[0m A new study created in memory with name: no-name-e4bc4e00-b1b2-4240-8915-d444e9c8f9bb\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 21.51GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 22:07:04,162]\u001b[0m Trial 0 finished with value: -242.0 and parameters: {'batch_size': 128, 'gamma': 0.9451145877858746, 'learning_rate': 0.0004383452677909998, 'learning_starts': 40000, 'train_freq': 256, 'gradient_steps': 163, 'exploration_final_eps': 0.013566620533055912, 'exploration_fraction': 0.1910647685409276}. Best is trial 0 with value: -242.0.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 22:20:54,373]\u001b[0m Trial 1 finished with value: -224.0 and parameters: {'batch_size': 1024, 'gamma': 0.9773401278300756, 'learning_rate': 0.00021919592900047344, 'learning_starts': 40000, 'train_freq': 256, 'gradient_steps': 46, 'exploration_final_eps': 0.06386208813128622, 'exploration_fraction': 0.21014339423128578}. Best is trial 1 with value: -224.0.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 21.54GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 22:37:11,321]\u001b[0m Trial 2 finished with value: 118.59999999999998 and parameters: {'batch_size': 64, 'gamma': 0.8227895970029786, 'learning_rate': 0.00018734229803741371, 'learning_starts': 1000, 'train_freq': 128, 'gradient_steps': 146, 'exploration_final_eps': 0.03317328152571017, 'exploration_fraction': 0.14405883869380742}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 21.55GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 22:53:10,589]\u001b[0m Trial 3 finished with value: -288.0 and parameters: {'batch_size': 32, 'gamma': 0.8206849468664695, 'learning_rate': 0.0006830266897568294, 'learning_starts': 10000, 'train_freq': 128, 'gradient_steps': 178, 'exploration_final_eps': 0.08532443706553289, 'exploration_fraction': 0.3494043691381584}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 21.53GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 23:04:17,683]\u001b[0m Trial 4 finished with value: -156.0 and parameters: {'batch_size': 1024, 'gamma': 0.9327934420986829, 'learning_rate': 0.0009677942071042495, 'learning_starts': 10000, 'train_freq': 256, 'gradient_steps': 20, 'exploration_final_eps': 0.026553808686750204, 'exploration_fraction': 0.3276185257224583}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 23:14:02,371]\u001b[0m Trial 5 finished with value: -241.0 and parameters: {'batch_size': 512, 'gamma': 0.8123319439034549, 'learning_rate': 0.0008257213806650403, 'learning_starts': 30000, 'train_freq': 256, 'gradient_steps': 33, 'exploration_final_eps': 0.025182518952958838, 'exploration_fraction': 0.3364802131423634}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 23:23:06,247]\u001b[0m Trial 6 finished with value: -273.23999999999995 and parameters: {'batch_size': 512, 'gamma': 0.9530994965416777, 'learning_rate': 0.0007650813880887576, 'learning_starts': 50000, 'train_freq': 256, 'gradient_steps': 35, 'exploration_final_eps': 0.0511233421034751, 'exploration_fraction': 0.3164474999972091}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-12 23:36:08,379]\u001b[0m Trial 7 finished with value: -277.0 and parameters: {'batch_size': 128, 'gamma': 0.999435315205845, 'learning_rate': 0.0009788718953183527, 'learning_starts': 20000, 'train_freq': 256, 'gradient_steps': 198, 'exploration_final_eps': 0.0735214633683788, 'exploration_fraction': 0.46142895976116016}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "/home/tony/.local/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 64.02GB > 21.52GB\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-02-12 23:46:32,627]\u001b[0m Trial 8 finished with value: -249.0 and parameters: {'batch_size': 64, 'gamma': 0.8609822849535325, 'learning_rate': 3.1589605770158345e-05, 'learning_starts': 20000, 'train_freq': 256, 'gradient_steps': 97, 'exploration_final_eps': 0.08767306693971323, 'exploration_fraction': 0.30677043871102827}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 00:03:17,181]\u001b[0m Trial 9 finished with value: -214.0 and parameters: {'batch_size': 32, 'gamma': 0.9801405522726507, 'learning_rate': 0.00015229974522043929, 'learning_starts': 1000, 'train_freq': 128, 'gradient_steps': 180, 'exploration_final_eps': 0.054068695928045175, 'exploration_fraction': 0.35794809556978646}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 00:17:19,945]\u001b[0m Trial 10 finished with value: -249.0 and parameters: {'batch_size': 64, 'gamma': 0.8797985369859828, 'learning_rate': 0.0003786671151096747, 'learning_starts': 1000, 'train_freq': 128, 'gradient_steps': 101, 'exploration_final_eps': 0.03511890971778165, 'exploration_fraction': 0.10459275140129556}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 00:46:56,245]\u001b[0m Trial 11 finished with value: -172.0 and parameters: {'batch_size': 256, 'gamma': 0.9159284965288541, 'learning_rate': 0.0005919201058586807, 'learning_starts': 10000, 'train_freq': 128, 'gradient_steps': 246, 'exploration_final_eps': 0.03555364545897058, 'exploration_fraction': 0.22197568396762804}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 01:41:31,583]\u001b[0m Trial 12 finished with value: -241.0 and parameters: {'batch_size': 1024, 'gamma': 0.9116982732506769, 'learning_rate': 0.0009996816655510627, 'learning_starts': 1000, 'train_freq': 128, 'gradient_steps': 121, 'exploration_final_eps': 0.034250134281137844, 'exploration_fraction': 0.4479577641092827}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 01:49:07,685]\u001b[0m Trial 13 finished with value: -221.0 and parameters: {'batch_size': 64, 'gamma': 0.8557968153779679, 'learning_rate': 0.00030212097560891203, 'learning_starts': 10000, 'train_freq': 128, 'gradient_steps': 2, 'exploration_final_eps': 0.016825296085647194, 'exploration_fraction': 0.10091996231438694}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 02:15:30,271]\u001b[0m Trial 14 finished with value: -187.0 and parameters: {'batch_size': 1024, 'gamma': 0.9383823842042486, 'learning_rate': 3.476685890952186e-05, 'learning_starts': 50000, 'train_freq': 128, 'gradient_steps': 74, 'exploration_final_eps': 0.02539682410272428, 'exploration_fraction': 0.25323621597739154}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 02:28:13,446]\u001b[0m Trial 15 finished with value: -234.0 and parameters: {'batch_size': 256, 'gamma': 0.8392514555369662, 'learning_rate': 0.0005585058729918486, 'learning_starts': 30000, 'train_freq': 256, 'gradient_steps': 144, 'exploration_final_eps': 0.04544271343393905, 'exploration_fraction': 0.4123644592856126}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 02:42:28,906]\u001b[0m Trial 16 finished with value: -277.0 and parameters: {'batch_size': 64, 'gamma': 0.8826612393687908, 'learning_rate': 0.00019509918457492713, 'learning_starts': 1000, 'train_freq': 256, 'gradient_steps': 213, 'exploration_final_eps': 0.02357187965224893, 'exploration_fraction': 0.15715636800463023}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 03:40:18,157]\u001b[0m Trial 17 finished with value: -277.64 and parameters: {'batch_size': 1024, 'gamma': 0.8034437873930034, 'learning_rate': 0.0008474108319909664, 'learning_starts': 10000, 'train_freq': 128, 'gradient_steps': 137, 'exploration_final_eps': 0.04279440920522971, 'exploration_fraction': 0.2691463429238641}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 03:50:09,474]\u001b[0m Trial 18 finished with value: -260.15999999999997 and parameters: {'batch_size': 64, 'gamma': 0.9263693764306155, 'learning_rate': 0.00046129314113291806, 'learning_starts': 10000, 'train_freq': 256, 'gradient_steps': 73, 'exploration_final_eps': 0.060650390382524115, 'exploration_fraction': 0.40584973787442896}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-02-13 04:01:36,775]\u001b[0m Trial 19 finished with value: -277.0 and parameters: {'batch_size': 1024, 'gamma': 0.8908656719597997, 'learning_rate': 0.0006389344250076938, 'learning_starts': 1000, 'train_freq': 128, 'gradient_steps': 10, 'exploration_final_eps': 0.03837206357224064, 'exploration_fraction': 0.49324549650649174}. Best is trial 2 with value: 118.59999999999998.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'gamma': 0.8227895970029786,\n",
       " 'learning_rate': 0.00018734229803741371,\n",
       " 'learning_starts': 1000,\n",
       " 'train_freq': 128,\n",
       " 'gradient_steps': 146,\n",
       " 'exploration_final_eps': 0.03317328152571017,\n",
       " 'exploration_fraction': 0.14405883869380742}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kLogDir = './logs_DQN_OP'\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_dqn_agent, n_trials=20)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b939a77a-c44d-4db3-8f08-59af5e69355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DQN.json', 'w') as outfile:\n",
    "    json.dump(study.best_params, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
